---
permalink: /
title: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---
I am a Postdoctoral Research Fellow at the Technical University of Vienna (TU Wien), working with [Prof. Dongheui Lee](https://www.tuwien.at/etit/ict/asl/team/dongheui-lee). My research focuses on advancing safe and efficient human-robot collaboration through robotics and control theory. I apply concepts from nonlinear control and robot learning to various manipulators and grasping systems.

I completed my Ph.D. in Mechanical Engineering at IIT Gandhinagar in 2024, where I worked alongside [Prof. Harish PM](https://iitgn.ac.in/faculty/me/6-harish) to develop human-inspired learning controllers and motion planners for robotic manipulators. My academic journey has been enriched by international research experiences, including visiting researcher positions at TU Wien, focusing on shared human-robot autonomy, and at the University of Texas at Austin, where I worked on single-degree-of-freedom gait training devices.

I have been fortunate to receive several recognitions for my work, including a gold medal at IIT Gandhinagarâ€™s 13th convocation. My research has been supported by multiple grants, such as the DST NIDHI PRAYAS grant for developing an adaptive motion controller, the IEEE RAS Student Travel Grant, the SPARC Travel Grant for my work at UT Austin, and the IITGN Overseas Research Fellowship for my research at TU Wien. I also had the honor of winning the regional Boeing BUILD Bootcamp for startups.

News
======
1. May 2025: Happy to share that our paper "Demonstrating REASSEMBLE: A Multimodal Dataset for Contact-rich Robotic Assembly and Disassembly" has been accepted to Robotics: Science and Systems (RSS 2025)
1. May 2024: I completed my Ph.D. at IIT Gandhinagar, earning a gold medal in recognition of outstanding innovation.
1. May 2024: I presented our paper 'Shared Autonomy via Variable Impedance Control and Virtual Potential Fields for Encoding Human Demonstrations' at ICRA 2024 in Yokohama, Japan.

<!-- Getting started
======
1. Register a GitHub account if you don't have one and confirm your e-mail (required!)
1. Fork [this template](https://github.com/academicpages/academicpages.github.io) by clicking the "Use this template" button in the top right. 
1. Go to the repository's settings (rightmost item in the tabs that start with "Code", should be below "Unwatch"). Rename the repository "[your GitHub username].github.io", which will also be your website's URL.
1. Set site-wide configuration and create content & metadata (see below -- also see [this set of diffs](http://archive.is/3TPas) showing what files were changed to set up [an example site](https://getorg-testacct.github.io) for a user with the username "getorg-testacct")
1. Upload any files (like PDFs, .zip files, etc.) to the files/ directory. They will appear at https://[your GitHub username].github.io/files/example.pdf.  
1. Check status by going to the repository settings, in the "GitHub pages" section

Site-wide configuration
------
The main configuration file for the site is in the base directory in [_config.yml](https://github.com/academicpages/academicpages.github.io/blob/master/_config.yml), which defines the content in the sidebars and other site-wide features. You will need to replace the default variables with ones about yourself and your site's github repository. The configuration file for the top menu is in [_data/navigation.yml](https://github.com/academicpages/academicpages.github.io/blob/master/_data/navigation.yml). For example, if you don't have a portfolio or blog posts, you can remove those items from that navigation.yml file to remove them from the header. 

Create content & metadata
------
For site content, there is one markdown file for each type of content, which are stored in directories like _publications, _talks, _posts, _teaching, or _pages. For example, each talk is a markdown file in the [_talks directory](https://github.com/academicpages/academicpages.github.io/tree/master/_talks). At the top of each markdown file is structured data in YAML about the talk, which the theme will parse to do lots of cool stuff. The same structured data about a talk is used to generate the list of talks on the [Talks page](https://academicpages.github.io/talks), each [individual page](https://academicpages.github.io/talks/2012-03-01-talk-1) for specific talks, the talks section for the [CV page](https://academicpages.github.io/cv), and the [map of places you've given a talk](https://academicpages.github.io/talkmap.html) (if you run this [python file](https://github.com/academicpages/academicpages.github.io/blob/master/talkmap.py) or [Jupyter notebook](https://github.com/academicpages/academicpages.github.io/blob/master/talkmap.ipynb), which creates the HTML for the map based on the contents of the _talks directory). -->

<!-- **Markdown generator**

The repository includes [a set of Jupyter notebooks](https://github.com/academicpages/academicpages.github.io/tree/master/markdown_generator
) that converts a CSV containing structured data about talks or presentations into individual markdown files that will be properly formatted for the Academic Pages template. The sample CSVs in that directory are the ones I used to create my own personal website at stuartgeiger.com. My usual workflow is that I keep a spreadsheet of my publications and talks, then run the code in these notebooks to generate the markdown files, then commit and push them to the GitHub repository. -->

Publications
======
<div style="display: flex; align-items: flex-start; margin-bottom: 1.5em;">
  <img src="/images/papers/reassamble.gif" alt="REASSEMBLE Thumbnail" style="width: 240px; margin-right: 10px; border: 1px solid #ddd;" />

  <div>
    <strong>REASSEMBLE: A Multimodal Dataset for Contact-rich Robotic Assembly and Disassembly</strong><br>
    Daniel Sliwowski, <strong>Shail Jadav</strong>, Sergej Stanovcic, Johannes Heidersberger, Jedrzej Orbik, Dongheui Lee<br>
    <span style="color:#ff7878;"><em>Robotics: Science and Systems (RSS 2025)</em></span><br>
    <span style="color:rgb(141, 141, 141);"><em>We release a multimodal dataset for long-horizon contact-rich assembly and disassembly tasks.</em></span><br>
    <a href="https://tuwien-asl.github.io/REASSEMBLE_page/">ğŸ”— Project Page</a> &nbsp; | &nbsp;
    <a href="https://arxiv.org/pdf/2502.05086">ğŸ“„ PDF</a> &nbsp; | &nbsp;
    <a href="https://arxiv.org/abs/2502.05086">ğŸ“ arXiv</a>
  </div>
</div>
<div style="display: flex; align-items: flex-start; margin-bottom: 1.5em;">
  <img src="/images/papers/icra.gif" alt="REASSEMBLE Thumbnail" style="width: 240px; margin-right: 10px; border: 1px solid #ddd;" />

  <div>
    <strong>Shared Autonomy via Variable Impedance Control and Virtual Potential Fields for Encoding Human Demonstrations</strong><br>
   <strong>Shail Jadav</strong>, Johannes Heidersberger, Christian Ott, Dongheui Lee<br>
    <span style="color:#ff7878;"><em> IEEE International Conference on Robotics and Automation (ICRA) 2024</em></span><br>
    <span style="color:rgb(141, 141, 141);"><em>This article introduces a framework for complex human-robot collaboration tasks, such as the co-manufacturing of furniture.</em></span><br>
    <a href="https://shailjadav.github.io/SALADS/">ğŸ”— Project Page</a> &nbsp; | &nbsp;
    <a href="https://arxiv.org/pdf/2403.12720">ğŸ“„ PDF</a> &nbsp; | &nbsp;
    <a href="https://arxiv.org/abs/2403.12720">ğŸ“ arXiv</a>
  </div>
</div>
<div style="display: flex; align-items: flex-start; margin-bottom: 1.5em;">
  <img src="/images/papers/vilc.gif" alt="REASSEMBLE Thumbnail" style="width: 240px; margin-right: 10px; border: 1px solid #ddd;" />

  <div>
    <strong>Configuration and force-field aware variable impedance control with faster re-learning</strong><br>
    <strong>Shail Jadav</strong>, & Harish J Palanthandalam-Madapusi<br>
    <span style="color:#ff7878;"><em>Springer Journal of Intelligent & Robotic Systems (2024)</em></span><br>
    <span style="color:rgb(141, 141, 141);"><em>We introduce an innovative VIC algorithm that addresses typical VIC challenges. </em></span><br>
    <!-- <a href="https://tuwien-asl.github.io/REASSEMBLE_page/">ğŸ”— Project Page</a> &nbsp; | &nbsp; -->
    <a href="https://link.springer.com/content/pdf/10.1007/s10846-023-02022-x.pdf">ğŸ“„ PDF</a> &nbsp; | &nbsp;
    <a href="https://link.springer.com/article/10.1007/s10846-023-02022-x">ğŸ“ Link</a>
  </div>
</div>

<div style="display: flex; align-items: flex-start; margin-bottom: 1.5em;">
  <img src="/images/papers/PDEYE4.gif" alt="REASSEMBLE Thumbnail" style="width: 240px; margin-right: 10px; border: 1px solid #ddd;" />

  <div>
    <strong>A Machine-Learning-Based Method to Detect Degradation of Motor Control Stability with Implications to Diagnosis of Presymptomatic Parkinsonâ€™s Disease: A Simulation Study</strong><br>
    Vrutangkumar V Shah, <strong>Shail Jadav</strong>, Sachin Goyal, Harish J Palanthandalam-Madapusi<br>
    <span style="color:#ff7878;"><em>MDPI Applied Sciences (2023)</em></span><br>
    <span style="color:rgb(141, 141, 141);"><em>We introduce an innovative ml & control theory based method for early diagnosis of Parkinsonâ€™s disease. </em></span><br>
    <!-- <a href="https://tuwien-asl.github.io/REASSEMBLE_page/">ğŸ”— Project Page</a> &nbsp; | &nbsp; -->
    <a href="https://www.mdpi.com/2076-3417/13/17/9502/pdf?version=1692703223">ğŸ“„ PDF</a> &nbsp; | &nbsp;
    <a href="https://www.mdpi.com/2076-3417/13/17/9502">ğŸ“ Link</a>
  </div>
</div>

<div style="display: flex; align-items: flex-start; margin-bottom: 1.5em;">
  <img src="/images/papers/gt.gif" alt="REASSEMBLE Thumbnail" style="width: 240px; margin-right: 10px; border: 1px solid #ddd;" />

  <div>
    <strong>Kinematic Performance of a Customizable Single Degree-of-Freedom Gait Trainer for Cost-Effective Therapy Aimed at Neuromuscular Impairments</strong><br>
     <strong>Shail Jadav </strong>, Karthik Subramanya Karvaje, Sujay D. Kadam, Vineet Vashista, James Sulzer, Ashish Deshpande, Harish J. Palanthandalam-Madapusi<br>
    <span style="color:#ff7878;"><em>ASME Journal of Medical Devices (2024)</em></span><br>
    <span style="color:rgb(141, 141, 141);"><em>We advance the development of a single degree-of-freedom (DOF) gait trainer for gait therapy for individuals with neuromuscular impairments. </em></span><br>
    <!-- <a href="https://tuwien-asl.github.io/REASSEMBLE_page/">ğŸ”— Project Page</a> &nbsp; | &nbsp; -->
    <a href="https://watermark.silverchair.com/med_018_01_011003.pdf?token=AQECAHi208BE49Ooan9kkhW_Ercy7Dm3ZL_9Cf3qfKAc485ysgAABIQwggSABgkqhkiG9w0BBwagggRxMIIEbQIBADCCBGYGCSqGSIb3DQEHATAeBglghkgBZQMEAS4wEQQMjbfCgZESx43uOq7tAgEQgIIENy4UtEMMIA9KXGwPTtz0vexkSFslttyoDoQl-RgVvaxdalny365GoVjHc72dWH4kGsTihQbqnVA0FMy2kDpOa4DLRE_H-NZnqs9cPbupUe5dq9UwN_8TvxLTGwOAATCTfTW_qk6LkAfa-RWamYD2L1LnZ0dJ9BdsJDWE3CZFwNEe2XHGV6XGEgV2--F1lCNIqQlNIR0cwDXSitGzSpeO_0-BC-vpZ5ZRTp8uS4MtY7HCLdbGu3YXzGxc0aS2XmCJYKciswJyy6n0vvtZawr4s3tC5GsF3sr3GosNx9rOlA_J2pKd8MHlyXhd5Py4inylX3Bikvh_-48d4Ju02kLqHolQU3lk5Wq5xwoPQiJnTnvEFIT_y7U_GVKPOZf0D_-ptOWgQlJ4K-i-x0l3iffZPVmeDpThHIMEVvVYloNn2qGUNHtPkZ68igagniuMuDH4HsbSCwuoV0I96PkqJ9ONy6ST7VTjuDNlYwsg4yon235Darycq3RM7Zp-SaGhcNwxmxj9ICpU-WO_CrZwuryKkrltelZS_GuZyX6oS0WHCuc-ACGAcg5RDBplFKXra1vafGssCNiInFu-ACwfG80ntcz5yHIjsuD7PPnKVEQDk8fKYaOujLY_tFkawhkNvD8pYgUWPT3I204pn9I0k6ZX1oR2o-Nr08C0njFK8PGK9mutGkcMzCJT33PTWS8lFHg25zc22czZO7R1mgKKlvZ5tGynDottEPYyJWdL7IOGkx081dxzbfhS-oI3KazDhmC-WAfyMD0jS_3AG6f8bJ5OvV8qpLc6vcXemZmGHLnwjeGctQBOvxxK-JBOJSt7fvmzRzhc_WEjeZKgvDGOrJqfecPgbUxQSjWpqI_6dqx5eECqtfTxvPUtCCjVtXU4Ls4A_ODINnS_xZEwgi0qZc6IpZdgX8xUICDxEuLz5Ev5scrvYKSyik6c3svBdLWQxPnUHnI-cj56Hwr0NDaaSghZZHYQBsD5MNOtppWhq_tduNRvprFkhV7oBq9QS6aVpv_8COP0F_GEyi_Qp9n1luW0d7-sYc10VqUn9DrD2zlXEHf-GQZuYZQrw_kBYvokT0Z01tyo2K6Qi8ha7UFjnRi7guCDSYXKASmRNDm6k8q1CgpzIa5iI8bgEfrnh2jNVA08mcfoTOyuuoXSJeCokqHaYEVfLvuUrfYSWc6zKJcB0pFqtjBXV4JVuiF5loemWyA-ydWCSisp-r8aJ4DtNAvblSK1EKBDDVRkJAGzH9Qi5w5RtTafWaG_vyEw3Xz7tJqN8NLLKXaamdobyyjCRF8_PqbjLBXMMSpk9pzRM1uxDQ35rbH7PKSOh2a5ZgqGgBPgXx8T2D26FM6fUuiJZj8eX22aVr7ROiOJ_z7lOO3NdO7veP_J3DfwpEFQRUQ9Ew_nXTPb8VbYQqmjWD1Z_yuJUAvYQB-9zYL7">ğŸ“„ PDF</a> &nbsp; | &nbsp;
    <a href="https://asmedigitalcollection.asme.org/medicaldevices/article/18/1/011003/1198715/Kinematic-Performance-of-a-Customizable-Single">ğŸ“ Link</a>
  </div>
</div>


<div style="display: flex; align-items: flex-start; margin-bottom: 1.5em;">
  <img src="/images/papers/red_asme.gif" alt="REASSEMBLE Thumbnail" style="width: 240px; margin-right: 10px; border: 1px solid #ddd;" />

  <div>
    <strong>Utilization of Manipulator Redundancy for Torque Reduction During Force Interaction</strong><br>
    <strong>Shail Jadav</strong>, & Harish J Palanthandalam-Madapusi<br>
    <span style="color:#ff7878;"><em>ASME Letters in Dynamic Systems and Control  (2024)</em></span><br>
    <span style="color:rgb(141, 141, 141);"><em>This paper introduces a novel objective function that responds to all external disturbances at the end-effector, aiming to lower joint torques via redundancy for precise trajectory tracking amidst disturbances. </em></span><br>
    <!-- <a href="https://tuwien-asl.github.io/REASSEMBLE_page/">ğŸ”— Project Page</a> &nbsp; | &nbsp; -->
    <a href="https://asmedigitalcollection.asme.org/lettersdynsys/article-pdf/4/2/021005/7246126/aldsc_4_2_021005.pdf">ğŸ“„ PDF</a> &nbsp; | &nbsp;
    <a href="https://asmedigitalcollection.asme.org/lettersdynsys/article/4/2/021005/1195452">ğŸ“ Link</a>
  </div>
</div>

More on my Google Scholar -> <a href="https://scholar.google.com/citations?user=n81CLlAAAAAJ&hl=en">ğŸ“ Link</a>




<!-- For more info
------
More info about configuring Academic Pages can be found in [the guide](https://academicpages.github.io/markdown/), the [growing wiki](https://github.com/academicpages/academicpages.github.io/wiki), and you can always [ask a question on GitHub](https://github.com/academicpages/academicpages.github.io/discussions). The [guides for the Minimal Mistakes theme](https://mmistakes.github.io/minimal-mistakes/docs/configuration/) (which this theme was forked from) might also be helpful. -->
